{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9],\n",
      "        [4],\n",
      "        [1],\n",
      "        [7],\n",
      "        [6]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 5\n",
    "nb_digits = 10\n",
    "# Dummy input that HAS to be 2D for the scatter (you can use view(-1,1) if needed)\n",
    "y = torch.LongTensor(batch_size,1).random_() % nb_digits\n",
    "# One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "y_onehot = torch.FloatTensor(batch_size, nb_digits)\n",
    "\n",
    "# In your for loop\n",
    "y_onehot.zero_()\n",
    "y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "print(y)\n",
    "print(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "num_classes = 10\n",
    "\n",
    "token_ids = torch.LongTensor(batch_size,seq_len).random_() % nb_digits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 0, 9, 0],\n",
       "        [7, 5, 8, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "onehots = torch.zeros(batch_size, seq_len, num_classes)\n",
    "onehots.scatter_(dim=2, index=token_ids.unsqueeze(2), value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9328008450>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.zeros(2,3)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        x[i,j] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.zeros(2,3)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        y[i,j] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = torch.ones(3,3)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        w0[i,j] = j\n",
    "w0 = torch.nn.Parameter(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [0., 1., 2.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.ones(3,3)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        w1[i,j] = j\n",
    "w1 = torch.nn.Parameter(w1)\n",
    "\n",
    "w2 = torch.ones(3,3)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        w2[i,j] = j\n",
    "w2 = torch.nn.Parameter(w2)\n",
    "\n",
    "w3 = torch.ones(3,3)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        w3[i,j] = j + 2\n",
    "w3 = torch.nn.Parameter(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=None\n",
    "l2=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = w3\n",
    "adv1 = w1\n",
    "adv2 = w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD((g,adv1,adv2), lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[2., 3., 4.],\n",
      "        [2., 3., 4.],\n",
      "        [2., 3., 4.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0., 1., 2.],\n",
      "        [0., 1., 2.],\n",
      "        [0., 1., 2.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0., 1., 2.],\n",
      "        [0., 1., 2.],\n",
      "        [0., 1., 2.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(g)\n",
    "print(adv1)\n",
    "print(adv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute grads for generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(g.grad)\n",
    "print(adv1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(g.grad)\n",
    "print(adv1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv1.requires_grad=False # HAVE TO BE CALLED BEFORE FORWARD!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = x.matmul(w3) \n",
    "l1 = tmp.matmul(w1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(g.grad)\n",
    "print(adv1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adv1.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(g.grad)\n",
    "print(adv1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute grads for discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2=tmp.detach() \n",
    "l2 = tmp2.matmul(w1).sum() # might be differnet from l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = l1+l2\n",
    "l3.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 6.,  6.,  6.],\n",
      "        [12., 12., 12.]])\n",
      "tensor([[12., 12., 12.],\n",
      "        [18., 18., 18.],\n",
      "        [24., 24., 24.]])\n"
     ]
    }
   ],
   "source": [
    "print(g.grad)\n",
    "print(adv1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 6.,  6.,  6.],\n",
      "        [12., 12., 12.]])\n",
      "tensor([[12., 12., 12.],\n",
      "        [18., 18., 18.],\n",
      "        [24., 24., 24.]])\n"
     ]
    }
   ],
   "source": [
    "print(g.grad)\n",
    "print(adv1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 2.,  3.,  4.],\n",
      "        [-1.,  0.,  1.],\n",
      "        [-4., -3., -2.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ -6.,  -5.,  -4.],\n",
      "        [ -9.,  -8.,  -7.],\n",
      "        [-12., -11., -10.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0., 1., 2.],\n",
      "        [0., 1., 2.],\n",
      "        [0., 1., 2.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(g)\n",
    "print(adv1)\n",
    "print(adv2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:konstrukt]",
   "language": "python",
   "name": "conda-env-konstrukt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
